{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = torchvision.transforms.ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_data\n",
    "\n",
    "test_data # 제출시 이 test 데이터에 대한 정확도를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.flatten(train_data.data/255, start_dim=1).float()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, hidden_sizes, output_size = 28*28, [256,128], 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size, hidden_sizes[0]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_sizes[1], output_size),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_data.targets\n",
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_epoch = 200\n",
    "def train(model, criterion, optimizer, nums_epoch, X, y):\n",
    "    for epoch in range(nums_epoch):\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if(epoch%5 == 0):\n",
    "            prediction = y_pred.max(1)[1]\n",
    "            corrects = (prediction == y)\n",
    "            accuracy = corrects.sum().float() / float( y.size(0))\n",
    "            print(epoch, \"loss=\", loss.item(), \"accu=\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= 2.3026974201202393 accu= 0.11423332989215851\n",
      "5 loss= 1.9008971452713013 accu= 0.6180166602134705\n",
      "10 loss= 1.6749368906021118 accu= 0.7986500263214111\n",
      "15 loss= 1.593430757522583 accu= 0.8739333152770996\n",
      "20 loss= 1.5631884336471558 accu= 0.900783360004425\n",
      "25 loss= 1.5488955974578857 accu= 0.9139000177383423\n",
      "30 loss= 1.537419319152832 accu= 0.9253833293914795\n",
      "35 loss= 1.527522087097168 accu= 0.9350500106811523\n",
      "40 loss= 1.5199809074401855 accu= 0.9427833557128906\n",
      "45 loss= 1.5132497549057007 accu= 0.9496999979019165\n",
      "50 loss= 1.5079418420791626 accu= 0.9549499750137329\n",
      "55 loss= 1.5033525228500366 accu= 0.9594333171844482\n",
      "60 loss= 1.4993871450424194 accu= 0.9635999798774719\n",
      "65 loss= 1.4960334300994873 accu= 0.9668999910354614\n",
      "70 loss= 1.4933176040649414 accu= 0.9697833061218262\n",
      "75 loss= 1.4910610914230347 accu= 0.971916675567627\n",
      "80 loss= 1.4890943765640259 accu= 0.9737499952316284\n",
      "85 loss= 1.4874308109283447 accu= 0.9751666784286499\n",
      "90 loss= 1.485974907875061 accu= 0.9765166640281677\n",
      "95 loss= 1.484722375869751 accu= 0.977733314037323\n",
      "100 loss= 1.4835611581802368 accu= 0.9788500070571899\n",
      "105 loss= 1.482622504234314 accu= 0.9796333312988281\n",
      "110 loss= 1.4816426038742065 accu= 0.9805999994277954\n",
      "115 loss= 1.4807558059692383 accu= 0.9813666939735413\n",
      "120 loss= 1.480008602142334 accu= 0.9819999933242798\n",
      "125 loss= 1.4793980121612549 accu= 0.9824833273887634\n",
      "130 loss= 1.478866457939148 accu= 0.9828833341598511\n",
      "135 loss= 1.4783464670181274 accu= 0.9833166599273682\n",
      "140 loss= 1.4778631925582886 accu= 0.9837833046913147\n",
      "145 loss= 1.4774399995803833 accu= 0.9842333197593689\n",
      "150 loss= 1.4770673513412476 accu= 0.9845166802406311\n",
      "155 loss= 1.4766926765441895 accu= 0.9849333167076111\n",
      "160 loss= 1.476395845413208 accu= 0.9851333498954773\n",
      "165 loss= 1.4760966300964355 accu= 0.9854000210762024\n",
      "170 loss= 1.4758166074752808 accu= 0.9856666922569275\n",
      "175 loss= 1.4755662679672241 accu= 0.9858499765396118\n",
      "180 loss= 1.4753237962722778 accu= 0.9861166477203369\n",
      "185 loss= 1.4751238822937012 accu= 0.9862666726112366\n",
      "190 loss= 1.4749441146850586 accu= 0.9864000082015991\n",
      "195 loss= 1.4747546911239624 accu= 0.9866499900817871\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, nums_epoch, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X)\n",
    "prediction = y_pred.max(1)[1]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
